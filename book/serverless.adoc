== Serverless architecture

Serverless Architecture あるいは Serverless Computing とは， 従来とは全くアプローチの異なるクラウドシステムの設計方法である．
歴史的には， AWS が2014年に発表した https://aws.amazon.com/lambda/[Lamba] がサーバーレスアーキテクチャの最初の先駆けとされている．
その後， Google や Microsoft などのクラウドプラットフォームも同様の機能の提供を開始している．
サーバーレスアーキテクチャの利点は，スケーラブルなクラウドシステムを安価かつ簡易に作成できる点であり，近年いたるところで導入が進んでいる．

Serverless とは，文字通りの意味としてはサーバーなしで計算をするということになるが，それは一体どういう意味だろうか？
サーバーレスについて説明するためには，まずは従来的な， "serverful" と呼ばれるようなシステムについて解説しなければならない．

[[chap_serverful_cloud]]
=== Serverful クラウド (従来型)

従来的なクラウドシステムのスケッチを <<serverful>> に示す．
クライアントから送信されたリクエストは，まず最初にAPIサーバーに送られる．
API サーバーでは，リクエストの内容に応じてタスクが実行される．
タスクには，APIサーバーだけで完結できるものもあるが，多くの場合，データベースの読み書きが必要である．
データベースには，データベース専用の独立したサーバーマシンが用いられることが一般的である．
また，画像や動画などもデータは，また別のストレージサーバーに保存されることが一般的である．
これらの APIサーバー，データベースサーバー，ストレージサーバーはそれぞれ独立したサーバーマシンであり， AWS では EC2 を使った仮想インスタンスを想定してもらったら良い．

多くのウェブサービスでは，多数のクライアントからのリクエストを処理するため，複数のサーバーマシンがクラウド内で起動し，負荷を分散するような設計がなされている．
クライアントから来たリクエストを計算容量に余裕のあるサーバーに振り分けるような操作を **Load balancing** とよび，そのような操作を担当するマシンのことを **Load balancer** という． 

Load balancing の目的でたくさんのインスタンスを起動するのはよいのだが，それぞれがなんの計算もせず，ただ新しいタスクが来るのを待っているようではコストと電力の無駄遣いである．
したがって，全てのサーバーが常に目標とする計算負荷を維持するよう，計算の負荷に応じてクラスター内の仮想サーバーの数を動的に増減させるような仕組みが必要である．
そのような仕組みを**クラスターのスケーリング**とよび，負荷の増大に応答して新しい仮想インスタンスをクラスターに追加する操作を **scale-out**，負荷の減少に応答してインスタンスをシャットダウンする操作を **scale-in** と呼ぶ．
クラスターのスケーリングは，各インスタンスを監視・統括するようなひとつ階層が上のサーバーを配置することで自動的に実行されるような設計がなされる．
クラスターのスケーリングは， API サーバーではもちろんのこと，データベースサーバー・ストレージサーバーでも必要になることが多い．
**クラウドシステム内すべてのインスタンスで，負荷が均一になるような調整が必要なのである．**

[[serverful]]
.Serverful なクラウドシステム
image::imgs/serverful.png[serverful, 700, align="center"]

=== Serverless クラウドへ

上述したように，従来のクラウドシステムの設計で非常に重要なのが，クラスターのスケーリングである．
コストパフォーマンスを最大化するには，各サーバーの稼働率を100%に近づけるようなスケーリングのパラメータの調整が必要である．
しかしながら，クラスターのスケーリングの最適化はかなり手間のかかる作業である．

さらに問題を複雑にするのは，APIサーバーで処理されるべきタスクが，非一様である点である．
非一様であるとは，例えばタスクAは3000ミリ秒の実行時間と 512MB のメモリーを消費し，別のタスクBは1000ミリ秒の実行時間と 128MB のメモリーを消費する，というような状況を差している．
一つのサーバーマシンが計算負荷が異なる複数のタスクを処理する場合，クラスターのスケーリングはより複雑になる．
この状況をシンプルにするために，１サーバーで実行するタスクは１種類に限る，という設計も可能であるが，そうするとで生まれる弊害も多い (ほとんど使われないタスクに対してもサーバー一台をまるまる割り当てなければならない = ほとんどアイドリング状態になってしまう，など)．

もっとシンプルで見通しの良いクラウドシステムのスケーリングの仕組みはないだろうか？

従来の serverful なシステムでの最大の問題点は，**サーバーをまるまる占有してしまう**という点にある．
すなわち， EC2 インスタンスを起動したとき，そのインスタンスは起動したユーザーだけが使えるものであり，**計算のリソース (CPUやRAM) が独占的に割り当てられた状態**になる．
固定した計算資源の割り当てがされてしまっているので，**インスタンスの計算負荷が0%であろうが100%であろうが，均一の使用料金が起動時間に比例**して発生する．

サーバーレスアーキテクチャは，このような **独占的に割り当てられた計算リソースというものを完全に廃止する．**
サーバーレスアーキテクチャでは，計算のリソースは，クラウドプロバイダーが全て管理する．
クライアントは，仮想インスタンスを一台まるごと借りるのではなく，**実行したいプログラムをクラウドに提出する**．
クラウドプロバイダーは，自身の持つ巨大な計算リソースから空きを探し，提出されたプログラムを実行し，実行結果をクライアントに返す．
以上を図示すると， <<serverless>> のようになる．

[[serverless]]
.従来のクラウドと Serverless クラウドの比較
image::imgs/serverless.png[serverless, 700, align="center"]

サーバーレスクラウドを利用することで，**クラウドのコストは実際に使用した計算の総量 (CPU稼働時間) で決定される**ことになる．
これは，計算の実行総量に関わらずインスタンスの起動時間で料金が決定されていた従来のシステムと比べて大きな違いである．
一方で，クライアントが同時に大量のタスクを送信した場合でも，クラウドプロバイダー側はその需要に応えることのできるような計算リソースを瞬時に割り当てることができるので，非常に高いスケーラビリティを実現することができる．

[NOTE]
====
従来型の(仮想インスタンスをたくさん起動するような)クラウドシステムは，**賃貸**と似ているかもしれない．
部屋を借りるというのは，その部屋でどれだけの時間を過ごそうが，月々の家賃は一定である．
同様に，仮想サーバーも，それがどれほどの計算を行っているかに関わらず，一定の料金が時間ごとに発生する．

一方で，サーバーレスクラウドは，**電気・水道・ガス料金** と似ている．
こちらは， (ある程度の基本料金はあるかもしれないが) 実際に使用した分で料金が決定されている．
サーバーレスクラウドも，実際に計算を行った総時間で料金が決まる仕組みになっている．
====

=== Lambda

image:imgs/aws_logos/Lambda.png[Lambda, 100]

AWS でサーバーレスコンピューティングの中心を担うのが， https://aws.amazon.com/lambda/[Lambda] である．

Lambda の使い方を <<lambda_workflow>> に図示している．
Lambda の仕組みはシンプルで，まずユーザーは実行したいプログラムを予め登録しておく．
プログラムは， Python, node.js, ruby などの主要な言語がサポートされている．
そして，プログラムを実行したいときに，そのプログラムを実行 (invoke する)コマンドを Lambda に送信する．
Lambda では， invoke のリクエストを受け取ると直ちに (数ミリセカンドから数百ミリセカンドのレイテンシーで) プログラムの実行を開始する．
そして，実行結果をクライアントやその他の計算機に返す．

[[lambda_workflow]]
.AWS Lambda
image::imgs/lambda_workflow.png[lambda_workflow, 500, align="center"]

このように，Lambda は仮想インスタンスを専有することはない．
invoke のリクエストが来たときにのみ，動的に起動し，実行の終了とともに速やかにシャットダウンされる．
また，同時に複数のリクエストが来た場合でも， AWS はそれらを実行するための計算リソースを割り当て，並列的に処理を行ってくれる．
原理上は，**数千から数万のリクエストが同時に来たとしても， Lambda はそれらを同時に実行することができる**．
このような，占有された仮想サーバーの存在なしに，動的に関数を実行するサービスを **FaaS (Function as a Service)** と呼ぶ．

Lambda では 128MB から 3008MB のメモリーを使用することができる (2020/06時点)．
実行時間は100ミリ秒の単位で記録され，実行時間に比例して料金が決定される．
<<lambda_pricing>> は Lambda の利用料金の利用料金表である．

[[lambda_pricing]]
[cols="1,1", options="header"] 
.Lambda の料金表
|===
|Memory (MB)
|Price per 100ms

|128
|$0.0000002083

|512
|$0.0000008333

|1024
|$0.0000016667

|3008
|$0.0000048958
|===

例えば， 128MB のメモリーを使用する関数を，それぞれ200ミリ秒，合計で100万回実行した場合，
0.0000002083 * 2 * 10^6 = **$0.4** の料金となる．
ウェブサーバーのデータベースの更新など簡単な計算であれば，200ミリ秒程度で実行できる関数も多いことから，100万回データベースの更新を行ったとしても，たった $0.4 しかコストが発生しないことになる．

=== サーバーレスストレージ: S3

image:imgs/aws_logos/S3.png[S3, 100]

サーバーレスの概念は，ストレージにも拡張されている．

従来的なストレージ (ファイルシステム) では，必ずホストとなるマシンと OS が存在しなければならない．
従って，それほどパワーは必要ないまでも，ある程度の CPU リソースを割かなければならない．
また，従来的なファイルシステムでは，データ領域のサイズは最初に作成するときに決めなければならず，後から容量を増加させることはしばしば困難である
(ZFS などのファイルシステムを使えばある程度は自由にファイルシステムのサイズを増減できるが)．
よって，従来的なクラウドでは，ストレージを借りるときには予めディスクのサイズを指定せねばならず，ディスクの容量が空であろうと満杯であろうと，同じ利用料金が発生することになる．

https://aws.amazon.com/s3/[Simple Storage Service (S3)] は，サーバーレスなストレージシステムを提供する．
S3 では，予めデータ保存領域の上限は定められていない．
データを入れれば入れた分だけ，保存領域は拡大していく
(仕様上はペタバイトスケールのデータを保存することが可能である)．
ストレージにかかる料金も，保存してあるデータの総容量で決定される．

その他，データの冗長化やバックアップなど，通常ならば CPU が介在しなければならない操作も， API を通じて行うことができる．
これらの観点から， S3 も サーバーレスクラウドの一部として取り扱われることが一般的である．

[[s3_vs_filesystem]]
.S3 と従来的なファイルシステムの比較
image::imgs/s3_vs_filesystem.png[s3_vs_filesystem, 700, align="center"]

S3 の料金は，保存してあるデータの総容量と，外部へのデータ転送の総量で決定される (https://aws.amazon.com/s3/pricing/?nc=sn&loc=4[参考])．
執筆時点では，データの保存には $0.025 per GB per month のコストが発生する．
従って，1000GB のデータを S3 に一ヶ月保存した場合， $25 の料金が発生することになる．
また， S3 はデータを外に取り出す際の通信にもコストが発生する．
執筆時点では，S3 からインターネットを通じて外部にデータを転送すると $0.114 per GB のコストが発生する．
データを S3 に入れる (data-in) 通信は無料で行える．
また， AWS の 同じ Region 内のサービス (Lambda など) にデータを転送するのは無料である．
AWS の Region をまたいだデータの転送には， $0.09 per GB のコストが発生する．

=== サーバーレスデータベース: DynamoDB

image:imgs/aws_logos/DynamoDB.png[S3, 100]

サーバーレスの概念は，データベースにも適用することができる．

ここでいうデータベースとは， Web サービスなどにおけるユーザー情報を記録しておくための保存領域のことを指している．
従来的に有名なデータベースとしては
https://www.mysql.com/[MySQL],
https://www.postgresql.org/[PostgreSQL],
https://www.mongodb.com/[MongoDB]
などが挙げられる．
データベースと普通のストレージの違いは，データの検索機能にある．
普通のストレージではデータは単純にディスクに書き込まれるだけだが，
データベースでは検索がより効率的になるようなデータの配置がされたり，
頻繁にアクセスされるデータはメモリーにキャッシュされるなどの機能が備わっている．
これにより，巨大なデータの中から，興味のある要素を高速に取得することができる．

このような検索機能を実現するには，当然 CPU の存在が必須である．
従って，従来的なデータベースを構築する際は，ストレージ領域に加えて，たくさんのCPUを搭載したマシンが用いられることが多い．
また，格納するデータが巨大な場合は複数マシンにまたがった分散型のシステムが設計される．
分散型システムの場合は， <<chap_serverful_cloud>> で議論したようにデータベースへのアクセス負荷に応じて適切なスケーリングがなされる必要がある．

https://aws.amazon.com/dynamodb/[DynamoDB] は，サーバーレスなデータベースである．

DynamoDB は分散型のデータベースであるが，データベースのスケーリングは AWS によって行われる．
ユーザーとしては，特になにも考えずに，送りたいだけのリクエストをデータベースに送信すればよい．
データベースへの負荷が増減したときのスケーリングは， DynamoDB が自動で行ってくれる．

=== その他のサーバーレスクラウドの構成要素

その他，サーバーレスクラウドを構成するための構成要素を以下にあげる．
API Gateway については，ハンズオン#5 で触れる．

* https://aws.amazon.com/api-gateway/[API Gateway]: API を構築する際のルーティングを担う．
* https://aws.amazon.com/fargate/[Fargate]: ハンズオン第三回で触れた Fargate も，サーバーレスクラウドの要素の一部である．
Lambda では実行できないような，メモリーや複数CPUを要するような計算などを行うために用いる．
* https://aws.amazon.com/sns/[Simple Notification Service (SNS)]: サーバーレスのサービス間 (Lambda と DynamoDB など) でイベントをやり取りするためのサービス．
* https://aws.amazon.com/step-functions/[Step Functions]: サーバーレスのサービス間のオーケストレーションを担う．

[TIP]
====
**サーバーレスアーキテクチャは万能か？**

この問への答えは，筆者は NO であると考える．

ここまで，サーバーレスの利点を強調して説明をしてきたが，まだまだ新しい技術なだけに，欠点，あるいはサーバーフルなシステムに劣る点は，数多くある．

ひとつ大きな欠点をあげるとすれば，サーバーレスのシステムは各クラウドプラットフォームに固有なものなので，特定のプラットフォームでしか運用できないシステムになってしまう点であろう．
AWS で作成したサーバーレスのシステムを， Google のクラウドに移植するには，かなり大掛かりなプログラムの書き換えが必要になる．
一方， serverful なシステムであれば，プラットフォーム間のマイグレーションは比較的簡単に行うことができる．
クラウドプロバイダーとしては，自社のシステムへの依存度を強めることで，顧客を離さないようにするという狙いがあるのだろう...

その他，サーバーレスコンピューティングの欠点や今後の課題などは，次の論文で詳しく議論されている．
興味のある読者は読んでみると良い．

* https://arxiv.org/abs/1812.03651[Hellerstein et al., "Serverless Computing: One Step Forward, Two Steps Back" arXiv (2018)]

====

