== Docker を用いた大規模機械学習システムの構築

ここまで， AWS 上に仮想サーバーを立ち上げ，ディープラーニングの計算を走らせる方法を紹介してきた．
ここまでは，**単一のサーバー**を立ち上げ，それにマニュアルでログインをして，コマンドを叩くことで計算を行ってきた．
いわば，__パーソナルコンピュータの延長__のような形でクラウドを使ってきたわけである．

このようなクラウドの使い方も，もちろん便利であるし，応用の可能性を広げるものである．
しかし，これだけではクラウドの本当の価値は十分に発揮されていない．
<<chap_cloud_basics>> で述べたように，現代的なクラウドの一番の強みは自由に計算機の規模を拡大できることにある．
すなわち，**多数のサーバーを同時に起動し，複数のジョブを分散並列的に実行させることで大量のデータを処理してこそ，クラウドの本領が発揮される**のである．

この章では，クラウドを使うことで，どのようにビッグデータの解析に立ち向かうのか，その片鱗をお見せしたい．
特に，前章で扱ったディープラーニングの計算を，どのようにビッグデータに適用していくかという点に焦点を絞って，議論していきたい．

=== 機械学習の大規模化

<<sec_scientific_computing>> で紹介した https://github.com/openai/gpt-3[GPT-3] のような，超巨大なディープラーニングのモデルを学習させたいとしよう．
そのような計算をクラウドで実行する場合は，典型的には <<big_dnn_training>> のようなアーキテクチャが用いられる．
すなわち，大量の教師データを，小さなチャンクとして複数のマシンに分散し，並列的にニューラルネットのパラメータを最適化していくという構造である．

[[big_dnn_training]]
.複数の計算機を使った大規模なディープラーニングモデルの学習
image::imgs/big_dnn_training.png[big_dnn_training, 700, align="center"]

あるいは，学習済みのモデルを大量にあるデータに適用し，解析を行いたいとしよう．
例えば，大量の動物の画像が与えられて，それぞれにラベルづけ (犬，猫，羊...) を行いたい場合などである．
そのような場合は， <<big_dnn_inference>> のようなアーキテクチャが考えられるだろう．
すなわち，大量のデータを複数のマシンで分割し，それぞれのマシンで推論の計算を行うというような構造である．

[[big_dnn_inference]]
.複数の計算機を使った大規模なディープラーニングモデルの学習
image::imgs/big_dnn_inference.png[big_dnn_inference, 700, align="center"]

このような複数の計算機を同時に走らせるようなアプリケーションをクラウド上で実現するには，どのようにすればよいのだろうか？

ひとつ重要なポイントとして， <<big_dnn_inference>> や <<big_dnn_inference>> で起動している複数のマシンは，**基本的に全く同一のOS・計算環境を有している**点である．
ここで，個人のコンピュータでやるようなインストールの操作を，各マシンで行うこともできるが，それは大変な手間であるし，メンテナンスも面倒だろう．
すなわち，大規模な計算システムを構築するには，**簡単に計算環境を複製できるような仕組み**が必要であるということがわかる．

そのような目的を実現するために使われるのが， https://www.docker.com/[Docker] と呼ばれるソフトウェアである．

=== Docker 概論

.Docker のロゴ
image::imgs/docker_log.png[docker, 500, align="center"]

Docker とは， **コンテナ (Container)** と呼ばれる仮想環境下で，ホストOSとは独立した別の計算環境を走らせるためのソフトウェアである．
Docker を使うことで， OS を含めた全てのプログラムをコンパクトにパッケージングすることが可能になる (パッケージされたひとつの計算環境のことを **イメージ (Image) **と呼ぶ)．
Dockerを使うことで，クラウドのサーバー上に瞬時に計算環境を複製することが可能になり，上で見たような複数の計算機を同時に走らせるためのシステムが実現できる．

Docker は2013年に Solomon Hykes らを中心に開発された．
概念としては， Docker は仮想マシン (Virtual machine; VM) にとても近い．
ここでは， VM との対比をしながら，Docker とはなにかを簡単に説明しよう．

仮想マシン(VM) とは，ホストとなるマシンの上に，仮想化されたOSを走らせる技術である (<<docker_vs_vm>>)．
VM には **ハイパーバイザー (Hypervisor)** と呼ばれるレイヤーが存在する．
Hypervisor はまず，物理的な計算機リソース (CPU, RAM, network など) を分割し，仮想化する．
例えば， 物理的にCPUが4コアあるとして，ハイパーバイザーはそれを (2,2) 個の組に仮想的に分割することができる．
VM 上で起動する OS には，ハイパーバイザーによって仮想化されたハードウェアが割り当てられる．
VM 上で起動する OS は基本的に完全に独立であり，例えば OS-A は OS-B に割り当てられたCPUやメモリー領域にアクセスすることはできない．
VM を作成するための有名なソフトウェアとしては， https://www.vmware.com/[VMware]， https://www.virtualbox.org/[VirtualBox]， https://xenproject.org/[Xen] などがある．
また，これまで触ってきた EC2 も，基本的に VM 技術によって実現されている．

Docker も， VM と同様に，仮想化された OS をホストのOS上に走らせるための技術である．
VM に対し， Docker ではハードウェアレベルの仮想化は行われておらず，すべての**仮想化はソフトウェアレベルで実現されている** (<<docker_vs_vm>>)．
Docker で走る仮想 OS は，**多くの部分をホストのOSに依存しており，結果として非常にコンパクトである**．
その結果， Docker で仮想 OS を起動するために要する時間は， VM に比べて圧倒的に早い．
また， image のサイズも完全なOSよりも圧倒的に小さくなるので，ネットワークを通じたやり取りが非常に高速化される点も重要である．
加えて， VM のいくつかの実装では，メタル (仮想化マシンではなく，物理的なハードウェアを使用した場合のこと) と比べ，ハイパーバイザーレイヤでのオーバーヘッドなどにより性能が低下することが知られているが， Docker ではメタルとほぼ同様の性能を引き出すことができるとされている．

その他， VM との相違点などはたくさんあるのだが，ここではこれ以上詳細には立ち入らない．
大事なのは， **Docker とはとても軽くてコンパクトな仮想計算環境を作るツールである**，という点である．
その手軽さゆえに，2013年の登場以降，クラウドシステムでの利用が急速に増加し，現代のクラウドでは欠くことのできない中心的な技術になっている．

[[docker_vs_vm]]
.Docker と VM の比較 (画像出典: https://www.docker.com/blog/containers-replacing-virtual-machines/)
image::imgs/docker_vs_vm.png[docker_vs_vm, 700, align="center"]

=== Docker の使い方

----
docker run -it ubuntu:18.04
----

Dockerfile


